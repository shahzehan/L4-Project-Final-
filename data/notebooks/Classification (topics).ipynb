{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4859863b-8853-440a-9dee-24d710658907",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import (\n",
    "   AutoConfig,\n",
    "   AutoTokenizer,\n",
    "   TFAutoModelForSequenceClassification,\n",
    "   AdamW,\n",
    "   glue_convert_examples_to_features\n",
    ")\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "import tensorflow as tf\n",
    "import sklearn\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "67e603dc-70d0-4ced-a856-7b95945f7576",
   "metadata": {
    "cellView": "both",
    "colab": {},
    "colab_type": "code",
    "id": "tyLIi4bvImJZ"
   },
   "outputs": [],
   "source": [
    "# Choose model\n",
    "# @markdown >The default model is <i><b>COVID-Twitter-BERT</b></i>. You can however choose <i><b>BERT Base</i></b> or <i><b>BERT Large</i></b> to compare these models to the <i><b>COVID-Twitter-BERT</i></b>. All these three models will be initiated with a random classification layer. If you go directly to the Predict-cell after having compiled the model, you will see that it still runs the predition. However the output will be random. The training steps below will finetune this for the specific task. <br /><br /> \n",
    "model_name = 'digitalepidemiologylab/covid-twitter-bert-v2' #@param [\"digitalepidemiologylab/covid-twitter-bert\", \"bert-large-uncased\", \"bert-base-uncased\"]\n",
    "\n",
    "# Initialise tokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name, do_lower_case=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "146d3a03-e38a-4534-abbf-4b35a7b15f50",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training Paremeters\n",
    "max_seq_length = 128 #@param {type: \"integer\"}\n",
    "train_batch_size =  8 #@param {type: \"integer\"} \n",
    "eval_batch_size = 8 #@param {type: \"integer\"}\n",
    "num_labels = 15\n",
    "\n",
    "# Loading the Training dataset\n",
    "t_train = pd.read_csv(\"..\\\\raw\\\\cluster_input.csv\", names=('text', 'label', 'topic', 'topic_label'))\n",
    "#t_train = t_train.sample(n=30000)\n",
    "\n",
    "#t_train[\"text\"] = t_train[\"text\"].apply(remove_contractions)\n",
    "#t_train[\"text\"] = t_train[\"text\"].apply(clean_text)\n",
    "#t_train.drop_duplicates(subset=[\"text\"], inplace=True)\n",
    "#t_train.dropna(inplace=True)\n",
    "\n",
    "#X_train = t_train[\"text\"][:len(df)*0.64]\n",
    "#X_val = t_train[\"text\"][len(df)*0.64:len(df)*0.8]\n",
    "#X_test = t_train[\"text\"][len(df)*0.8:]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(t_train['text'], t_train['topic_label'], test_size=0.2, random_state=1)\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.20, random_state=1) # 0.25 x 0.8 = 0.2\n",
    "\n",
    "train_text = []\n",
    "val_text = []\n",
    "test_text = []\n",
    "\n",
    "train_label = []\n",
    "val_label = []\n",
    "test_label = []\n",
    "\n",
    "for row in X_train:\n",
    "    train_text.append(str(row))\n",
    "    \n",
    "for row in X_val:\n",
    "    val_text.append(str(row))\n",
    "    \n",
    "for row in X_test:\n",
    "    test_text.append(str(row))\n",
    "    \n",
    "for row in y_train:\n",
    "    train_label.append(int(row))\n",
    "\n",
    "for row in y_val:\n",
    "    val_label.append(int(row))\n",
    "    \n",
    "for row in y_test:\n",
    "    test_label.append(int(row))\n",
    "\n",
    "#train_text = tokenizer(train_text, max_length=max_seq_length, truncation=True, padding=True)\n",
    "#val_text = tokenizer(val_text, max_length=max_seq_length, truncation=True, padding=True)\n",
    "#test_text = tokenizer(test_text, max_length=max_seq_length, truncation=True, padding=True)\n",
    "\n",
    "train = np.zeros([np.size(train_text), max_seq_length], dtype=int)\n",
    "val = np.zeros([np.size(val_text), max_seq_length], dtype=int)\n",
    "\n",
    "for i in range(len(train_text)):\n",
    "    tokens = np.asarray(tokenizer.encode(train_text[i], max_length=max_seq_length, truncation=True, padding=True))\n",
    "    for j in range(np.size(tokens)):\n",
    "        train[i][j] = tokens[j]\n",
    "\n",
    "for i in range(len(val_text)):\n",
    "    tokens = np.asarray(tokenizer.encode(val_text[i], max_length=max_seq_length, truncation=True, padding=True))\n",
    "    for j in range(np.size(tokens)):\n",
    "        val[i][j] = tokens[j]\n",
    "\n",
    "\n",
    "#a = tokenizer.encode(train_text[0], max_length=max_seq_length, truncation=True, padding=True)\n",
    "#print(np.shape(a))\n",
    "\n",
    "\n",
    "#train_text = np.asarray(train_text)\n",
    "#val_text = np.asarray(val_text)\n",
    "#test_text = np.asarray(test_text)\n",
    "\n",
    "train_label = np.asarray(train_label)\n",
    "val_label = np.asarray(val_label)\n",
    "test_label = np.array(test_label)\n",
    "\n",
    "label_mapping = {0:'Masks', 1:'Vaccine', 2:'Symptoms', 3:'Quarantine', 4:'Lockdown', 5:'Education', 6:'Treatment',\n",
    "                 7:'Science', 8:'Statistics', 9:'Health', 10:'Work', 11:'Legislation', 12:'Politics', 13:'Travel', 14:'Testing'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35e9652e-70b3-416d-bfee-870f3e990cb0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5b241b7f-0c49-48e4-ac4f-f6a6f9472735",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(9600,)\n",
      "[  101  2142  7608 28324  2015  2070  2859  7599  2044 21887 23350  8293\n",
      " 16770  1024  1013  1013  1056  1012  2522  1013 16950  4183  2860  2629\n",
      " 11106 26775 16770  1024  1013  1013  1056  1012  2522  1013  1060  9331\n",
      "  2290  2629  2497  2620 18037  2860   102     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0]\n",
      "[  101 10722 17140 18372  2250  2386  2013  2474  8289  2013  2522 17258\n",
      "  1011  2539  2420  2077  2010  7886  3367  5798 16770  1024  1013  1013\n",
      "  1056  1012  2522  1013  1041  2620  2232  2595  4213  2050 27531  2278\n",
      "  3081  1030  5925  2581  1001  2510  1001  5734  1001  7608 13832  4313\n",
      " 26634  1001  3909  1001 10722 17140 18372  1001  2088  9028  2475  1001\n",
      "  1059  2860  2475  1001  2088 20031  2072  1001  2510 15164  3508  1001\n",
      "  2510 24158  7062  1001  2250 14821  1001  3915 10867  2100  1001  3915\n",
      "  4313 14821  1001  2390 15164  3508  1001  2390   102     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0]\n"
     ]
    }
   ],
   "source": [
    "#train_t = tf.convert_to_tensor(train_text)\n",
    "#val_t = tf.convert_to_tensor(val_text)\n",
    "#test_t = tf.convert_to_tensor(test_text)\n",
    "#train_l = tf.convert_to_tensor(train_label)\n",
    "#val_l = tf.convert_to_tensor(val_label)\n",
    "#test_l = tf.convert_to_tensor(test_label)\n",
    "print(np.shape(train_text))\n",
    "\n",
    "np.shape(train)\n",
    "np.shape(train_label)\n",
    "\n",
    "#print(np.shape(train[0]))\n",
    "#print(np.shape(train[5]))\n",
    "print(train[0])\n",
    "print(train[5])\n",
    "#print(train_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a1c906ec-f8ac-48bc-9526-4a805abca863",
   "metadata": {
    "cellView": "both",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 695,
     "referenced_widgets": [
      "448f914b46b644f5851f1af379b6a4e1",
      "0b613b02dfe34bb682b4964c15808aff",
      "fe8a58e6570b47368d8af58c9f88252d",
      "def365577baa4c06964afa044aeaf6c2",
      "f0265fb7ba1b45f6a9f9187918bf549c",
      "d299f05a0190420cbee345284d7018a0",
      "3554e30180a0456f9f3aa5a08ebe1cdb",
      "299748a6b86041ab8dbdddef56b8a1c1"
     ]
    },
    "colab_type": "code",
    "id": "2XSbsZFDQTEO",
    "outputId": "2596ac65-32e7-4a2e-ef9b-5aaf2689d969"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "All model checkpoint layers were used when initializing TFBertForSequenceClassification.\n",
      "\n",
      "Some layers of TFBertForSequenceClassification were not initialized from the model checkpoint at digitalepidemiologylab/covid-twitter-bert-v2 and are newly initialized: ['classifier']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
      "WARNING:tensorflow:AutoGraph could not transform <bound method Socket.send of <zmq.Socket(zmq.PUSH) at 0x1e4b6b2ebe0>> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module, class, method, function, traceback, frame, or code object was expected, got cython_function_or_method\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <bound method Socket.send of <zmq.Socket(zmq.PUSH) at 0x1e4b6b2ebe0>> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module, class, method, function, traceback, frame, or code object was expected, got cython_function_or_method\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
      "WARNING:tensorflow:From C:\\Users\\shahzehan\\miniconda3\\envs\\dick\\lib\\site-packages\\tensorflow\\python\\ops\\array_ops.py:5043: calling gather (from tensorflow.python.ops.array_ops) with validate_indices is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "The `validate_indices` argument has no effect. Indices are always validated on CPU and never validated on GPU.\n",
      "WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
      "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
      "1200/1200 [==============================] - ETA: 0s - loss: 2.7467 - accuracy: 0.0665WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
      "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
      "1200/1200 [==============================] - 366s 281ms/step - loss: 2.7467 - accuracy: 0.0665 - val_loss: 2.7233 - val_accuracy: 0.0650\n",
      "Epoch 2/3\n",
      "  83/1200 [=>............................] - ETA: 4:51 - loss: 2.7287 - accuracy: 0.0753"
     ]
    },
    {
     "ename": "InternalError",
     "evalue": " 'cuModuleGetFunction(&function, module, kernel_name)' failed with 'CUDA_ERROR_INVALID_HANDLE'\n\t [[node tf_bert_for_sequence_classification/bert/encoder/layer_._23/output/LayerNorm/batchnorm/sub (defined at \\shahzehan\\miniconda3\\envs\\dick\\lib\\site-packages\\transformers\\models\\bert\\modeling_tf_bert.py:372) ]] [Op:__inference_train_function_33082]\n\nFunction call stack:\ntrain_function\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mInternalError\u001b[0m                             Traceback (most recent call last)",
      "\u001b[1;32mC:\\Users\\SHAHZE~1\\AppData\\Local\\Temp/ipykernel_7604/1744541128.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     32\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     33\u001b[0m \u001b[1;31m# Train the model\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 34\u001b[1;33m \u001b[0mhistory\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_label\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnum_epochs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtrain_steps_per_epoch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mval\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mval_label\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalidation_steps\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdev_steps_per_epoch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m8\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     35\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     36\u001b[0m '''\n",
      "\u001b[1;32m~\\miniconda3\\envs\\dick\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1181\u001b[0m                 _r=1):\n\u001b[0;32m   1182\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1183\u001b[1;33m               \u001b[0mtmp_logs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1184\u001b[0m               \u001b[1;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1185\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\miniconda3\\envs\\dick\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    887\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    888\u001b[0m       \u001b[1;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 889\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    890\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    891\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\miniconda3\\envs\\dick\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    915\u001b[0m       \u001b[1;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    916\u001b[0m       \u001b[1;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 917\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# pylint: disable=not-callable\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    918\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    919\u001b[0m       \u001b[1;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\miniconda3\\envs\\dick\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   3021\u001b[0m       (graph_function,\n\u001b[0;32m   3022\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[1;32m-> 3023\u001b[1;33m     return graph_function._call_flat(\n\u001b[0m\u001b[0;32m   3024\u001b[0m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[0;32m   3025\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\miniconda3\\envs\\dick\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1958\u001b[0m         and executing_eagerly):\n\u001b[0;32m   1959\u001b[0m       \u001b[1;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1960\u001b[1;33m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0m\u001b[0;32m   1961\u001b[0m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0;32m   1962\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n",
      "\u001b[1;32m~\\miniconda3\\envs\\dick\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36mcall\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    589\u001b[0m       \u001b[1;32mwith\u001b[0m \u001b[0m_InterpolateFunctionError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    590\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcancellation_manager\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 591\u001b[1;33m           outputs = execute.execute(\n\u001b[0m\u001b[0;32m    592\u001b[0m               \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msignature\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    593\u001b[0m               \u001b[0mnum_outputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_num_outputs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\miniconda3\\envs\\dick\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     57\u001b[0m   \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 59\u001b[1;33m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[0;32m     60\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[0;32m     61\u001b[0m   \u001b[1;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mInternalError\u001b[0m:  'cuModuleGetFunction(&function, module, kernel_name)' failed with 'CUDA_ERROR_INVALID_HANDLE'\n\t [[node tf_bert_for_sequence_classification/bert/encoder/layer_._23/output/LayerNorm/batchnorm/sub (defined at \\shahzehan\\miniconda3\\envs\\dick\\lib\\site-packages\\transformers\\models\\bert\\modeling_tf_bert.py:372) ]] [Op:__inference_train_function_33082]\n\nFunction call stack:\ntrain_function\n"
     ]
    }
   ],
   "source": [
    "#@markdown >The default learning rate of 2e5 will be fine in most cases\n",
    "learning_rate = 2e-5 #@param {type: \"number\"}\n",
    "\n",
    "#@markdown > Typically these type of models are finetuned for 3 epochs. This can be increased for small datasets and decreased for large datasets.\n",
    "num_epochs = 3 #@param {type: \"integer\"}\n",
    "\n",
    "# Initialise a Model for Sequence Classification with 2 labels\n",
    "config = AutoConfig.from_pretrained(model_name, num_labels=num_labels)\n",
    "model = TFAutoModelForSequenceClassification.from_pretrained(model_name, config=config)\n",
    "\n",
    "# Optimizer and loss\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate=learning_rate)\n",
    "loss = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)\n",
    "#loss = tf.keras.losses.BinaryCrossentropy(from_logits=True)\n",
    "\n",
    "# Metrics and callbacks no false negatives bitch\n",
    "metrics = [tf.keras.metrics.SparseCategoricalAccuracy('accuracy', dtype=tf.float32)]\n",
    "#metrics = [tf.keras.metrics.Recall(), tf.keras.metrics.Precision()]\n",
    "#checkpoint_path = '..\\\\cvb\\\\checkpoints\\\\checkpoint.{epoch:02d}'\n",
    "#callbacks = [tf.keras.callbacks.ModelCheckpoint(checkpoint_path, save_weights_only=True)]\n",
    "\n",
    "# Compute some variables\n",
    "use_percentage_of_data = 100\n",
    "train_steps_per_epoch = int(np.size(train[:,0]) * (use_percentage_of_data/100) / train_batch_size)\n",
    "dev_steps_per_epoch = int(np.size(val[:,0]) * (use_percentage_of_data/100) / eval_batch_size)\n",
    "#train_steps_per_epoch = 100\n",
    "#dev_steps_per_epoch = 100\n",
    "\n",
    "\n",
    "# Compile model\n",
    "model.compile(optimizer=optimizer, loss=loss, metrics=metrics)\n",
    "\n",
    "# Train the model\n",
    "history = model.fit(train, train_label, epochs=num_epochs, steps_per_epoch=train_steps_per_epoch, validation_data=(val, val_label), validation_steps=dev_steps_per_epoch, batch_size=8)\n",
    "\n",
    "'''\n",
    "# Print some information about the training\n",
    "print(f'\\nThe training has finished training after {num_epochs} epochs.')\n",
    "print('\\nThe history contains the accuracy and loss at every epoch:')\n",
    "print(json.dumps(history.history, indent=4))\n",
    "\n",
    "print('\\nThe checkpoint callback has generated a checkpoint after every epoch (loss being the training loss, val_loss is the validation loss):')\n",
    "!ls -lha ./checkpoints/\n",
    "\n",
    "print('\\nWe will now save the finetuned model and the corresponding config file on your Colab disk.')\n",
    "model.save_pretrained('..\\\\cvb\\\\huggingface_model\\\\')\n",
    "\n",
    "print('\\nTensorflow model and config-file is saved in ./huggingface_model/')\n",
    "!ls -lha ./huggingface_model/\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8134fa73-9b35-466d-9c87-c02d73870379",
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "0T0zy0fK9Rmx"
   },
   "outputs": [],
   "source": [
    "\n",
    "# Small function only used for formatting the output\n",
    "def format_prediction(preds, label_mapping, label_name):\n",
    "    preds = tf.nn.softmax(preds, axis=1)\n",
    "    formatted_preds = []\n",
    "    for pred in preds.numpy():\n",
    "        # convert to Python types and sort\n",
    "        pred = {label: float(probability) for label, probability in zip(label_mapping.values(), pred)}\n",
    "        pred = {k: v for k, v in sorted(pred.items(), key=lambda item: item[1], reverse=True)}\n",
    "        formatted_preds.append({label_name: list(pred.keys())[0], f'{label_name}_probabilities': pred})\n",
    "    return formatted_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ce36768-cbee-4a97-8dff-2bc452b2b9d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import fbeta_score\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "def evaluation_summary(description, predictions, true_labels):\n",
    "    print(\"Evaluation for: \" + description)\n",
    "    precision = precision_score(predictions, true_labels, average='macro')\n",
    "    recall = recall_score(predictions, true_labels, average='macro')\n",
    "    accuracy = accuracy_score(predictions, true_labels)\n",
    "    f1 = f1_score(predictions, true_labels, average='macro')\n",
    "    #f1 = fbeta_score(predictions, true_labels, 1, average='macro') #1 means f_1 measure\n",
    "    print(\"Classifier '%s' has Acc=%0.3f P=%0.3f R=%0.3f F1=%0.3f\" % (description,accuracy,precision,recall,f1))\n",
    "    print(classification_report(predictions, true_labels, digits=3, zero_division=0))\n",
    "    print('\\nConfusion matrix:\\n',confusion_matrix(true_labels, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52bf98b1-48ee-4958-9acd-cb24ba552b4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "test = np.zeros([np.size(test_text), max_seq_length], dtype=int)\n",
    "\n",
    "for i in range(len(test_text)):\n",
    "    tokens = np.asarray(tokenizer.encode(test_text[i], max_length=max_seq_length, truncation=True, padding=True))\n",
    "    for j in range(np.size(tokens)):\n",
    "        test[i][j] = tokens[j]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ce37235-5192-453f-bedf-e3a687fbf079",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_pred = model.predict(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4aeb8bd0-1dac-4288-ae1e-b915f3b8e58d",
   "metadata": {},
   "outputs": [],
   "source": [
    "formatted_test_preds = format_prediction(test_pred[0], label_mapping, 'fake?')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87c29846-866c-4d5a-b85e-2bde29397fd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_pred_labels = []\n",
    "for i in range(len(test_text)):\n",
    "    if (formatted_test_preds[i]['fake?_probabilities']['Real'] > 0.5):\n",
    "        test_pred_labels.append(0)\n",
    "    else:\n",
    "        test_pred_labels.append(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c481cc69-8300-4e4c-a56c-379b355a0091",
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluation_summary(\"Covid-Twitter-Bert-v2\", test_pred_labels, test_label)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

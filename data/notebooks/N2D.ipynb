{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "deccd1f4-c9ef-4808-a28d-1826e0fb559c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import os\n",
    "import random as rn\n",
    "\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "plt.style.use(['seaborn-white', 'seaborn-paper'])\n",
    "sns.set_context(\"paper\", font_scale=1.3)\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sys\n",
    "import tensorflow as tf\n",
    "import umap\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras.layers import Dense, Input\n",
    "from tensorflow.keras.models import Model\n",
    "from sklearn import metrics\n",
    "from sklearn import mixture\n",
    "from sklearn.cluster import KMeans, SpectralClustering\n",
    "from sklearn.manifold import Isomap\n",
    "from sklearn.manifold import LocallyLinearEmbedding\n",
    "from scipy.optimize import linear_sum_assignment as linear_assignment\n",
    "from time import time\n",
    "from sklearn.model_selection import train_test_split\n",
    "from transformers import (\n",
    "   AutoConfig,\n",
    "   AutoTokenizer,\n",
    "   TFAutoModelForSequenceClassification,\n",
    "   AdamW,\n",
    "   glue_convert_examples_to_features\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2f017352-8a1c-4f84-9f50-57a8b4f63930",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"CUDA_DEVICE_ORDER\"] = \"PCI_BUS_ID\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = str(sys.argv[2])\n",
    "os.environ['PYTHONHASHSEED'] = '0'\n",
    "os.environ['TF_CUDNN_USE_AUTOTUNE'] = '0'\n",
    "\n",
    "rn.seed(0)\n",
    "tf.random.set_seed(0)\n",
    "np.random.seed(0)\n",
    "\n",
    "#session_conf = tf.compat.v1.ConfigProto(intra_op_parallelism_threads=1, inter_op_parallelism_threads=1,)\n",
    "#sess = tf.compat.v1.Session(graph=tf.compat.v1.get_default_graph(), config=session_conf)\n",
    "#K.set_session(sess)\n",
    "np.set_printoptions(threshold=sys.maxsize)\n",
    "\n",
    "matplotlib.use('agg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bf343d2b-553d-493e-9eab-f2dd2d282a5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_other_methods(x, y, names=None):\n",
    "    gmm = mixture.GaussianMixture(\n",
    "        covariance_type='full',\n",
    "        n_components=n_clusters,\n",
    "        random_state=0)\n",
    "    gmm.fit(x)\n",
    "    y_pred_prob = gmm.predict_proba(x)\n",
    "    y_pred = y_pred_prob.argmax(1)\n",
    "    acc = np.round(cluster_acc(y, y_pred), 5)\n",
    "    nmi = np.round(metrics.normalized_mutual_info_score(y, y_pred), 5)\n",
    "    ari = np.round(metrics.adjusted_rand_score(y, y_pred), 5)\n",
    "    print(\"GMM clustering on raw data\")\n",
    "    print('=' * 80)\n",
    "    print(acc)\n",
    "    print(nmi)\n",
    "    print(ari)\n",
    "    print('=' * 80)\n",
    "\n",
    "    y_pred = KMeans(\n",
    "        n_clusters=n_clusters,\n",
    "        random_state=0).fit_predict(x)\n",
    "    acc = np.round(cluster_acc(y, y_pred), 5)\n",
    "    nmi = np.round(metrics.normalized_mutual_info_score(y, y_pred), 5)\n",
    "    ari = np.round(metrics.adjusted_rand_score(y, y_pred), 5)\n",
    "    print(\"K-Means clustering on raw data\")\n",
    "    print('=' * 80)\n",
    "    print(acc)\n",
    "    print(nmi)\n",
    "    print(ari)\n",
    "    print('=' * 80)\n",
    "\n",
    "    sc = SpectralClustering(\n",
    "        n_clusters=n_clusters,\n",
    "        random_state=0,\n",
    "        affinity='nearest_neighbors')\n",
    "    y_pred = sc.fit_predict(x)\n",
    "    acc = np.round(cluster_acc(y, y_pred), 5)\n",
    "    nmi = np.round(metrics.normalized_mutual_info_score(y, y_pred), 5)\n",
    "    ari = np.round(metrics.adjusted_rand_score(y, y_pred), 5)\n",
    "    print(\"Spectral Clustering on raw data\")\n",
    "    print('=' * 80)\n",
    "    print(acc)\n",
    "    print(nmi)\n",
    "    print(ari)\n",
    "    print('=' * 80)\n",
    "\n",
    "    if manifold_learner == 'UMAP':\n",
    "        md = float(umap_min_dist)\n",
    "        hle = umap.UMAP(\n",
    "            random_state=0,\n",
    "            metric=umap_metric,\n",
    "            n_components=umap_dim,\n",
    "            n_neighbors=umap_neighbors,\n",
    "            min_dist=md).fit_transform(x)\n",
    "    elif manifold_learner == 'LLE':\n",
    "        from sklearn.manifold import LocallyLinearEmbedding\n",
    "        hle = LocallyLinearEmbedding(\n",
    "            n_components=umap_dim,\n",
    "            n_neighbors=umap_neighbors).fit_transform(x)\n",
    "    elif manifold_learner == 'tSNE':\n",
    "        method = 'exact'\n",
    "        hle = TSNE(\n",
    "            n_components=umap_dim,\n",
    "            n_jobs=16,\n",
    "            random_state=0,\n",
    "            verbose=0).fit_transform(x)\n",
    "    elif manifold_learner == 'isomap':\n",
    "        hle = Isomap(\n",
    "            n_components=umap_dim,\n",
    "            n_neighbors=5,\n",
    "        ).fit_transform(x)\n",
    "\n",
    "    gmm = mixture.GaussianMixture(\n",
    "        covariance_type='full',\n",
    "        n_components=n_clusters,\n",
    "        random_state=0)\n",
    "    gmm.fit(hle)\n",
    "    y_pred_prob = gmm.predict_proba(hle)\n",
    "    y_pred = y_pred_prob.argmax(1)\n",
    "    acc = np.round(cluster_acc(y, y_pred), 5)\n",
    "    nmi = np.round(metrics.normalized_mutual_info_score(y, y_pred), 5)\n",
    "    ari = np.round(metrics.adjusted_rand_score(y, y_pred), 5)\n",
    "    print(\"GMM clustering on \" +\n",
    "          str(manifold_learner) + \" embedding\")\n",
    "    print('=' * 80)\n",
    "    print(acc)\n",
    "    print(nmi)\n",
    "    print(ari)\n",
    "    print('=' * 80)\n",
    "\n",
    "    if visualize:\n",
    "        plot(hle, y, 'UMAP', names)\n",
    "        y_pred_viz, _, _ = best_cluster_fit(y, y_pred)\n",
    "        plot(hle, y_pred_viz, 'UMAP-predicted', names)\n",
    "\n",
    "        return\n",
    "\n",
    "    y_pred = KMeans(\n",
    "        n_clusters=n_clusters,\n",
    "        random_state=0).fit_predict(hle)\n",
    "    acc = np.round(cluster_acc(y, y_pred), 5)\n",
    "    nmi = np.round(metrics.normalized_mutual_info_score(y, y_pred), 5)\n",
    "    ari = np.round(metrics.adjusted_rand_score(y, y_pred), 5)\n",
    "    print(dataset + \" | K-Means \" +\n",
    "          str(manifold_learner) + \" embedding\")\n",
    "    print('=' * 80)\n",
    "    print(acc)\n",
    "    print(nmi)\n",
    "    print(ari)\n",
    "    print('=' * 80)\n",
    "\n",
    "    sc = SpectralClustering(\n",
    "        n_clusters=n_clusters,\n",
    "        random_state=0,\n",
    "        affinity='nearest_neighbors')\n",
    "    y_pred = sc.fit_predict(hle)\n",
    "    acc = np.round(cluster_acc(y, y_pred), 5)\n",
    "    nmi = np.round(metrics.normalized_mutual_info_score(y, y_pred), 5)\n",
    "    ari = np.round(metrics.adjusted_rand_score(y, y_pred), 5)\n",
    "    print(dataset + \" | Spectral Clustering on \" +\n",
    "          str(manifold_learner) + \" embedding\")\n",
    "    print('=' * 80)\n",
    "    print(acc)\n",
    "    print(nmi)\n",
    "    print(ari)\n",
    "    print('=' * 80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b7f0d232-ee8a-44ba-a10f-95a4d1bff305",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cluster_manifold_in_embedding(hl, y, label_names=None):\n",
    "    # find manifold on autoencoded embedding\n",
    "    if manifold_learner == 'UMAP':\n",
    "        md = float(umap_min_dist)\n",
    "        hle = umap.UMAP(\n",
    "            random_state=0,\n",
    "            metric=umap_metric,\n",
    "            n_components=umap_dim,\n",
    "            n_neighbors=umap_neighbors,\n",
    "            min_dist=md).fit_transform(hl)\n",
    "    elif manifold_learner == 'LLE':\n",
    "        hle = LocallyLinearEmbedding(\n",
    "            n_components=umap_dim,\n",
    "            n_neighbors=umap_neighbors).fit_transform(hl)\n",
    "    elif manifold_learner == 'tSNE':\n",
    "        hle = TSNE(\n",
    "            n_components=umap_dim,\n",
    "            n_jobs=16,\n",
    "            random_state=0,\n",
    "            verbose=0).fit_transform(hl)\n",
    "    elif manifold_learner == 'isomap':\n",
    "        hle = Isomap(\n",
    "            n_components=umap_dim,\n",
    "            n_neighbors=5,\n",
    "        ).fit_transform(hl)\n",
    "\n",
    "    # clustering on new manifold of autoencoded embedding\n",
    "    if cluster == 'GMM':\n",
    "        gmm = mixture.GaussianMixture(\n",
    "            covariance_type='full',\n",
    "            n_components=n_clusters,\n",
    "            random_state=0)\n",
    "        gmm.fit(hle)\n",
    "        y_pred_prob = gmm.predict_proba(hle)\n",
    "        y_pred = y_pred_prob.argmax(1)\n",
    "    elif cluster == 'KM':\n",
    "        km = KMeans(\n",
    "            init='k-means++',\n",
    "            n_clusters=n_clusters,\n",
    "            random_state=0,\n",
    "            n_init=20)\n",
    "        y_pred = km.fit_predict(hle)\n",
    "    elif cluster == 'SC':\n",
    "        sc = SpectralClustering(\n",
    "            n_clusters=n_clusters,\n",
    "            random_state=0,\n",
    "            affinity='nearest_neighbors')\n",
    "        y_pred = sc.fit_predict(hle)\n",
    "\n",
    "    y_pred = np.asarray(y_pred)\n",
    "    # y_pred = y_pred.reshape(len(y_pred), )\n",
    "    y = np.asarray(y)\n",
    "    # y = y.reshape(len(y), )\n",
    "    acc = np.round(cluster_acc(y, y_pred), 5)\n",
    "    nmi = np.round(metrics.normalized_mutual_info_score(y, y_pred), 5)\n",
    "    ari = np.round(metrics.adjusted_rand_score(y, y_pred), 5)\n",
    "    print(manifold_learner +\n",
    "          \" on autoencoded embedding with \" + cluster + \" - N2D\")\n",
    "    print('=' * 80)\n",
    "    print(acc)\n",
    "    print(nmi)\n",
    "    print(ari)\n",
    "    print('=' * 80)\n",
    "\n",
    "    if visualize:\n",
    "        plot(hle, y, 'n2d', label_names)\n",
    "        y_pred_viz, _, _ = best_cluster_fit(y, y_pred)\n",
    "        plot(hle, y_pred_viz, 'n2d-predicted', label_names)\n",
    "\n",
    "    return y_pred, acc, nmi, ari"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ba446d21-ba20-4616-981e-4c6f239760ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "def best_cluster_fit(y_true, y_pred):\n",
    "    y_true = y_true.astype(np.int64)\n",
    "    D = max(y_pred.max(), y_true.max()) + 1\n",
    "    w = np.zeros((D, D), dtype=np.int64)\n",
    "    for i in range(y_pred.size):\n",
    "        w[y_pred[i], y_true[i]] += 1\n",
    "\n",
    "    ind = linear_assignment(w.max() - w)\n",
    "    best_fit = []\n",
    "    for i in range(y_pred.size):\n",
    "        for j in range(len(ind)):\n",
    "            if ind[j][0] == y_pred[i]:\n",
    "                best_fit.append(ind[j][1])\n",
    "    return best_fit, ind, w\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4d3df596-5a4d-4ca0-adee-db3ac7288691",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cluster_acc(y_true, y_pred):\n",
    "    _, ind, w = best_cluster_fit(y_true, y_pred)\n",
    "    return sum([w[i, j] for i, j in ind]) * 1.0 / y_pred.size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "09be65e6-3a84-47b1-9df6-91b210748f58",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot(x, y, plot_id, names=None):\n",
    "    viz_df = pd.DataFrame(data=x[:5000])\n",
    "    viz_df['Label'] = y[:5000]\n",
    "    if names is not None:\n",
    "        viz_df['Label'] = viz_df['Label'].map(names)\n",
    "\n",
    "    #viz_df.to_csv(args.save_dir + '/' + args.dataset + '.csv')\n",
    "    plt.subplots(figsize=(8, 5))\n",
    "    sns.scatterplot(x=0, y=1, hue='Label', legend='full', hue_order=sorted(viz_df['Label'].unique()),\n",
    "                    palette=sns.color_palette(\"hls\", n_colors=n_clusters),\n",
    "                    alpha=.5,\n",
    "                    data=viz_df)\n",
    "    l = plt.legend(bbox_to_anchor=(-.1, 1.00, 1.1, .5), loc=\"lower left\", markerfirst=True,\n",
    "                   mode=\"expand\", borderaxespad=0, ncol=n_clusters + 1, handletextpad=0.01, )\n",
    "\n",
    "    l.texts[0].set_text(\"\")\n",
    "    plt.ylabel(\"\")\n",
    "    plt.xlabel(\"\")\n",
    "    plt.tight_layout()\n",
    "    #plt.savefig(args.save_dir + '/' + args.dataset +\n",
    "                #'-' + plot_id + '.png', dpi=300)\n",
    "    plt.clf()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4adfa9b3-a7df-40c5-ae37-d1fc8a65d70b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def autoencoder(dims, act='relu'):\n",
    "    n_stacks = len(dims) - 1\n",
    "    x = Input(shape=(dims[0],), name='input')\n",
    "    h = x\n",
    "    for i in range(n_stacks - 1):\n",
    "        h = Dense(dims[i + 1], activation=act, name='encoder_%d' % i)(h)\n",
    "    h = Dense(dims[-1], name='encoder_%d' % (n_stacks - 1))(h)\n",
    "    for i in range(n_stacks - 1, 0, -1):\n",
    "        h = Dense(dims[i], activation=act, name='decoder_%d' % i)(h)\n",
    "    h = Dense(dims[0], name='decoder_0')(h)\n",
    "\n",
    "    return Model(inputs=x, outputs=h)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "576748a9-4718-4c5a-991a-7d1dffb4a7c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choose model\n",
    "# @markdown >The default model is <i><b>COVID-Twitter-BERT</b></i>. You can however choose <i><b>BERT Base</i></b> or <i><b>BERT Large</i></b> to compare these models to the <i><b>COVID-Twitter-BERT</i></b>. All these three models will be initiated with a random classification layer. If you go directly to the Predict-cell after having compiled the model, you will see that it still runs the predition. However the output will be random. The training steps below will finetune this for the specific task. <br /><br /> \n",
    "model_name = 'digitalepidemiologylab/covid-twitter-bert-v2' #@param [\"digitalepidemiologylab/covid-twitter-bert\", \"bert-large-uncased\", \"bert-base-uncased\"]\n",
    "\n",
    "# Initialise tokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name, do_lower_case=True)\n",
    "\n",
    "# Training Paremeters\n",
    "max_seq_length = 128 #@param {type: \"integer\"}\n",
    "train_batch_size =  8 #@param {type: \"integer\"} \n",
    "eval_batch_size = 8 #@param {type: \"integer\"}\n",
    "num_labels = 15\n",
    "\n",
    "# Loading the Training dataset\n",
    "t_train = pd.read_csv(\"..\\\\raw\\\\cluster_input.csv\", names=('text', 'label', 'topic', 'topic_label'))\n",
    "#t_train = t_train.sample(n=30000)\n",
    "\n",
    "#t_train[\"text\"] = t_train[\"text\"].apply(remove_contractions)\n",
    "#t_train[\"text\"] = t_train[\"text\"].apply(clean_text)\n",
    "#t_train.drop_duplicates(subset=[\"text\"], inplace=True)\n",
    "#t_train.dropna(inplace=True)\n",
    "\n",
    "#X_train = t_train[\"text\"][:len(df)*0.64]\n",
    "#X_val = t_train[\"text\"][len(df)*0.64:len(df)*0.8]\n",
    "#X_test = t_train[\"text\"][len(df)*0.8:]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(t_train['text'], t_train['topic_label'], test_size=0.2, random_state=1)\n",
    "#X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.20, random_state=1) # 0.25 x 0.8 = 0.2\n",
    "\n",
    "train_text = []\n",
    "#val_text = []\n",
    "test_text = []\n",
    "\n",
    "train_label = []\n",
    "#val_label = []\n",
    "test_label = []\n",
    "\n",
    "for row in X_train:\n",
    "    train_text.append(str(row))\n",
    "    \n",
    "#for row in X_val:\n",
    "    #val_text.append(str(row))\n",
    "    \n",
    "for row in X_test:\n",
    "    test_text.append(str(row))\n",
    "    \n",
    "for row in y_train:\n",
    "    train_label.append(int(row))\n",
    "\n",
    "#for row in y_val:\n",
    "    #val_label.append(int(row))\n",
    "    \n",
    "for row in y_test:\n",
    "    test_label.append(int(row))\n",
    "\n",
    "#train_text = tokenizer(train_text, max_length=max_seq_length, truncation=True, padding=True)\n",
    "#val_text = tokenizer(val_text, max_length=max_seq_length, truncation=True, padding=True)\n",
    "#test_text = tokenizer(test_text, max_length=max_seq_length, truncation=True, padding=True)\n",
    "\n",
    "train = np.zeros([np.size(train_text), max_seq_length], dtype=int)\n",
    "#val = np.zeros([np.size(val_text), max_seq_length], dtype=int)\n",
    "test = np.zeros([np.size(test_text), max_seq_length], dtype=int)\n",
    "\n",
    "for i in range(len(train_text)):\n",
    "    tokens = np.asarray(tokenizer.encode(train_text[i], max_length=max_seq_length, truncation=True, padding=True))\n",
    "    for j in range(np.size(tokens)):\n",
    "        train[i][j] = tokens[j]\n",
    "\n",
    "'''\n",
    "for i in range(len(val_text)):\n",
    "    tokens = np.asarray(tokenizer.encode(val_text[i], max_length=max_seq_length, truncation=True, padding=True))\n",
    "    for j in range(np.size(tokens)):\n",
    "        val[i][j] = tokens[j]\n",
    "'''\n",
    "\n",
    "for i in range(len(test_text)):\n",
    "    tokens = np.asarray(tokenizer.encode(test_text[i], max_length=max_seq_length, truncation=True, padding=True))\n",
    "    for j in range(np.size(tokens)):\n",
    "        test[i][j] = tokens[j]\n",
    "\n",
    "\n",
    "#a = tokenizer.encode(train_text[0], max_length=max_seq_length, truncation=True, padding=True)\n",
    "#print(np.shape(a))\n",
    "\n",
    "\n",
    "#train_text = np.asarray(train_text)\n",
    "#val_text = np.asarray(val_text)\n",
    "#test_text = np.asarray(test_text)\n",
    "\n",
    "train_label = np.asarray(train_label)\n",
    "#val_label = np.asarray(val_label)\n",
    "test_label = np.array(test_label)\n",
    "\n",
    "label_mapping = {0:'Masks', 1:'Vaccine', 2:'Symptoms', 3:'Quarantine', 4:'Lockdown', 5:'Education', 6:'Treatment',\n",
    "                 7:'Science', 8:'Statistics', 9:'Health', 10:'Work', 11:'Legislation', 12:'Politics', 13:'Travel', 14:'Testing'}\n",
    "\n",
    "label_names = ['Masks', 'Vaccine', 'Symptoms', 'Quarantine', 'Lockdown', 'Education', 'Treatment',\n",
    "                 'Science', 'Statistics', 'Health', 'Work', 'Legislation', 'Politics', 'Travel', 'Testing']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f3afd9c4-4ce3-4341-bd22-e18e4d9f2346",
   "metadata": {},
   "outputs": [],
   "source": [
    "global umap_dim\n",
    "global umap_neighbors\n",
    "global umap_min_dist\n",
    "global umap_metric\n",
    "global cluster\n",
    "global visualize\n",
    "global manifold_learner\n",
    "global n_clusters\n",
    "\n",
    "umap_dim = 2\n",
    "umap_neighbors = 10\n",
    "umap_min_dist = \"0.00\"\n",
    "umap_metric = 'euclidean'\n",
    "cluster = 'GMM' # options = GMM, KM and SC\n",
    "visualize = True\n",
    "manifold_learner = 'UMAP' # options = UMAP, LLE, tSNE, isomap\n",
    "n_clusters = 15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a42d55d4-0966-47fd-b4b6-ace235aad8ee",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "too many values to unpack (expected 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32mC:\\Users\\SHAHZE~1\\AppData\\Local\\Temp/ipykernel_9340/2241053494.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     16\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     17\u001b[0m \u001b[1;31m#hl = encoder.predict(train)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 18\u001b[1;33m \u001b[0meval_other_methods\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_label\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabel_names\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     19\u001b[0m \u001b[1;31m#clusters, t_acc, t_nmi, t_ari = cluster_manifold_in_embedding(hl, y, label_names)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\SHAHZE~1\\AppData\\Local\\Temp/ipykernel_9340/3827923495.py\u001b[0m in \u001b[0;36meval_other_methods\u001b[1;34m(x, y, names)\u001b[0m\n\u001b[0;32m      7\u001b[0m     \u001b[0my_pred_prob\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgmm\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict_proba\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m     \u001b[0my_pred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0my_pred_prob\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 9\u001b[1;33m     \u001b[0macc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mround\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcluster_acc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m5\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     10\u001b[0m     \u001b[0mnmi\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mround\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmetrics\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnormalized_mutual_info_score\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m5\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m     \u001b[0mari\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mround\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmetrics\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madjusted_rand_score\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m5\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\SHAHZE~1\\AppData\\Local\\Temp/ipykernel_9340/3983238282.py\u001b[0m in \u001b[0;36mcluster_acc\u001b[1;34m(y_true, y_pred)\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mcluster_acc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m     \u001b[0m_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mind\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mw\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbest_cluster_fit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0msum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mw\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mj\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mj\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mind\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m*\u001b[0m \u001b[1;36m1.0\u001b[0m \u001b[1;33m/\u001b[0m \u001b[0my_pred\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msize\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mC:\\Users\\SHAHZE~1\\AppData\\Local\\Temp/ipykernel_9340/3983238282.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mcluster_acc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m     \u001b[0m_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mind\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mw\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbest_cluster_fit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0msum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mw\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mj\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mj\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mind\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m*\u001b[0m \u001b[1;36m1.0\u001b[0m \u001b[1;33m/\u001b[0m \u001b[0my_pred\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msize\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m: too many values to unpack (expected 2)"
     ]
    }
   ],
   "source": [
    "optimizer = 'adam'\n",
    "\n",
    "#shape = [train.shape[-1], 500, 500, 2000, n_clusters]\n",
    "#autoencoder = autoencoder(shape)\n",
    "\n",
    "#hidden = autoencoder.get_layer(name='encoder_%d' % (len(shape) - 2)).output\n",
    "#encoder = Model(inputs=autoencoder.input, outputs=hidden)\n",
    "\n",
    "#pretrain_time = time()\n",
    "\n",
    "# Pretrain autoencoders before clustering\n",
    "#autoencoder.compile(loss='mse', optimizer=optimizer)\n",
    "#autoencoder.fit(train, train, batch_size=train_batch_size, epochs=10, verbose=0)\n",
    "\n",
    "#pretrain_time = time() - pretrain_time\n",
    "\n",
    "#hl = encoder.predict(train)\n",
    "eval_other_methods(train, train_label, label_names)\n",
    "#clusters, t_acc, t_nmi, t_ari = cluster_manifold_in_embedding(hl, y, label_names)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

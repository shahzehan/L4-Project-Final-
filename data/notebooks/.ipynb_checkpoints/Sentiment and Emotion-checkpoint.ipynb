{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "de9015e0-666b-4c21-938c-430fe03bcf26",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "import sklearn\n",
    "import os\n",
    "from pysentimiento import create_analyzer\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9378d3c0-3bdc-40be-a428-e4807551e006",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading configuration file https://huggingface.co/finiteautomata/bertweet-base-sentiment-analysis/resolve/main/config.json from cache at C:\\Users\\shahzehan/.cache\\huggingface\\transformers\\cb09766f7ba60b5f7a1bb640617b24f1499c4a6f3ab160c4a0ac171e3a377c68.008dca06003188334001a96363da79ced4944abc68d94a2f1e0db786dc5aa08b\n",
      "Model config RobertaConfig {\n",
      "  \"_name_or_path\": \"finiteautomata/bertweet-base-sentiment-analysis\",\n",
      "  \"architectures\": [\n",
      "    \"RobertaForSequenceClassification\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"bos_token_id\": 0,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"NEG\",\n",
      "    \"1\": \"NEU\",\n",
      "    \"2\": \"POS\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"label2id\": {\n",
      "    \"NEG\": 0,\n",
      "    \"NEU\": 1,\n",
      "    \"POS\": 2\n",
      "  },\n",
      "  \"layer_norm_eps\": 1e-05,\n",
      "  \"max_position_embeddings\": 130,\n",
      "  \"model_type\": \"roberta\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"problem_type\": \"single_label_classification\",\n",
      "  \"tokenizer_class\": \"BertweetTokenizer\",\n",
      "  \"transformers_version\": \"4.17.0\",\n",
      "  \"type_vocab_size\": 1,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 64001\n",
      "}\n",
      "\n",
      "loading file https://huggingface.co/finiteautomata/bertweet-base-sentiment-analysis/resolve/main/vocab.txt from cache at C:\\Users\\shahzehan/.cache\\huggingface\\transformers\\973dbacfdf4c488622f01d1a226089e9e3dba130a0c3c11c2e36d49466fa40a8.f8a4dfe5c3c45a26f9df849d732decb191dc0c05ab270799695430332d143982\n",
      "loading file https://huggingface.co/finiteautomata/bertweet-base-sentiment-analysis/resolve/main/bpe.codes from cache at C:\\Users\\shahzehan/.cache\\huggingface\\transformers\\0e474c44ff353f3b378fb140e7e6d4431df4ec6142e8b38d584c0dbc5afc3521.75877d86011e5d5d46614d3a21757b705e9d20ed45a019805d25159b4837b0a4\n",
      "loading file https://huggingface.co/finiteautomata/bertweet-base-sentiment-analysis/resolve/main/added_tokens.json from cache at C:\\Users\\shahzehan/.cache\\huggingface\\transformers\\fe46927817477a58ec2aa92ef52f8ee6fc9e824d054f4aa6a3c129724dc9c9b7.c1e7052e39d2135302ec27455f6db22e1520e6539942ff60a849c7f83f8ec6dc\n",
      "loading file https://huggingface.co/finiteautomata/bertweet-base-sentiment-analysis/resolve/main/special_tokens_map.json from cache at C:\\Users\\shahzehan/.cache\\huggingface\\transformers\\9413ac0bed76140860deffa0c5a29ee4da7d49a3810da1b4b51b27f790bc9255.0dc5b1041f62041ebbd23b1297f2f573769d5c97d8b7c28180ec86b8f6185aa8\n",
      "loading file https://huggingface.co/finiteautomata/bertweet-base-sentiment-analysis/resolve/main/tokenizer_config.json from cache at C:\\Users\\shahzehan/.cache\\huggingface\\transformers\\61374b71c02fdfd2929a3cdce24c242049e036624e15e18461a3a70cfc35e939.c260b44e952f7f2a825aac395f2ebbed4ac9553800d1e320af246e81a548f37c\n",
      "loading configuration file https://huggingface.co/finiteautomata/bertweet-base-sentiment-analysis/resolve/main/config.json from cache at C:\\Users\\shahzehan/.cache\\huggingface\\transformers\\cb09766f7ba60b5f7a1bb640617b24f1499c4a6f3ab160c4a0ac171e3a377c68.008dca06003188334001a96363da79ced4944abc68d94a2f1e0db786dc5aa08b\n",
      "Model config RobertaConfig {\n",
      "  \"_name_or_path\": \"finiteautomata/bertweet-base-sentiment-analysis\",\n",
      "  \"architectures\": [\n",
      "    \"RobertaForSequenceClassification\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"bos_token_id\": 0,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"NEG\",\n",
      "    \"1\": \"NEU\",\n",
      "    \"2\": \"POS\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"label2id\": {\n",
      "    \"NEG\": 0,\n",
      "    \"NEU\": 1,\n",
      "    \"POS\": 2\n",
      "  },\n",
      "  \"layer_norm_eps\": 1e-05,\n",
      "  \"max_position_embeddings\": 130,\n",
      "  \"model_type\": \"roberta\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"problem_type\": \"single_label_classification\",\n",
      "  \"tokenizer_class\": \"BertweetTokenizer\",\n",
      "  \"transformers_version\": \"4.17.0\",\n",
      "  \"type_vocab_size\": 1,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 64001\n",
      "}\n",
      "\n",
      "Adding <mask> to the vocabulary\n",
      "loading configuration file https://huggingface.co/finiteautomata/bertweet-base-sentiment-analysis/resolve/main/config.json from cache at C:\\Users\\shahzehan/.cache\\huggingface\\transformers\\cb09766f7ba60b5f7a1bb640617b24f1499c4a6f3ab160c4a0ac171e3a377c68.008dca06003188334001a96363da79ced4944abc68d94a2f1e0db786dc5aa08b\n",
      "Model config RobertaConfig {\n",
      "  \"_name_or_path\": \"finiteautomata/bertweet-base-sentiment-analysis\",\n",
      "  \"architectures\": [\n",
      "    \"RobertaForSequenceClassification\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"bos_token_id\": 0,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"NEG\",\n",
      "    \"1\": \"NEU\",\n",
      "    \"2\": \"POS\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"label2id\": {\n",
      "    \"NEG\": 0,\n",
      "    \"NEU\": 1,\n",
      "    \"POS\": 2\n",
      "  },\n",
      "  \"layer_norm_eps\": 1e-05,\n",
      "  \"max_position_embeddings\": 130,\n",
      "  \"model_type\": \"roberta\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"problem_type\": \"single_label_classification\",\n",
      "  \"tokenizer_class\": \"BertweetTokenizer\",\n",
      "  \"transformers_version\": \"4.17.0\",\n",
      "  \"type_vocab_size\": 1,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 64001\n",
      "}\n",
      "\n",
      "loading weights file https://huggingface.co/finiteautomata/bertweet-base-sentiment-analysis/resolve/main/pytorch_model.bin from cache at C:\\Users\\shahzehan/.cache\\huggingface\\transformers\\2e4719cf8d097772eb75070b88cbc56f1d3b1392fffc5f75032a389ef21d1847.16366ca1277caccb15200478349503b3336a1420ac26d44fc16763354f5a2cae\n",
      "All model checkpoint weights were used when initializing RobertaForSequenceClassification.\n",
      "\n",
      "All the weights of RobertaForSequenceClassification were initialized from the model checkpoint at finiteautomata/bertweet-base-sentiment-analysis.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use RobertaForSequenceClassification for predictions without further training.\n",
      "PyTorch: setting up devices\n",
      "The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n",
      "loading configuration file https://huggingface.co/finiteautomata/bertweet-base-emotion-analysis/resolve/main/config.json from cache at C:\\Users\\shahzehan/.cache\\huggingface\\transformers\\c246eed05359b1a49c45955b0265b488e35b0cbd2628e3ead7dd54c8815162ee.a2dff24b4e0a884c6d58a09968c5b68e7391e749eb698ad92541818d420fd01b\n",
      "Model config RobertaConfig {\n",
      "  \"_name_or_path\": \"finiteautomata/bertweet-base-emotion-analysis\",\n",
      "  \"architectures\": [\n",
      "    \"RobertaForSequenceClassification\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"bos_token_id\": 0,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"others\",\n",
      "    \"1\": \"joy\",\n",
      "    \"2\": \"sadness\",\n",
      "    \"3\": \"anger\",\n",
      "    \"4\": \"surprise\",\n",
      "    \"5\": \"disgust\",\n",
      "    \"6\": \"fear\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"label2id\": {\n",
      "    \"anger\": 3,\n",
      "    \"disgust\": 5,\n",
      "    \"fear\": 6,\n",
      "    \"joy\": 1,\n",
      "    \"others\": 0,\n",
      "    \"sadness\": 2,\n",
      "    \"surprise\": 4\n",
      "  },\n",
      "  \"layer_norm_eps\": 1e-05,\n",
      "  \"max_position_embeddings\": 130,\n",
      "  \"model_type\": \"roberta\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"tokenizer_class\": \"BertweetTokenizer\",\n",
      "  \"transformers_version\": \"4.17.0\",\n",
      "  \"type_vocab_size\": 1,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 64001\n",
      "}\n",
      "\n",
      "loading file https://huggingface.co/finiteautomata/bertweet-base-emotion-analysis/resolve/main/vocab.txt from cache at C:\\Users\\shahzehan/.cache\\huggingface\\transformers\\b7837213513a9f3852dcb04048f70c13cbd0590be030e534734ffd42cbdcf45a.f8a4dfe5c3c45a26f9df849d732decb191dc0c05ab270799695430332d143982\n",
      "loading file https://huggingface.co/finiteautomata/bertweet-base-emotion-analysis/resolve/main/bpe.codes from cache at C:\\Users\\shahzehan/.cache\\huggingface\\transformers\\76e357e2554ebe053d1c4c613506bc2cc19d66ae27fec8218261a7f73c6456b9.75877d86011e5d5d46614d3a21757b705e9d20ed45a019805d25159b4837b0a4\n",
      "loading file https://huggingface.co/finiteautomata/bertweet-base-emotion-analysis/resolve/main/added_tokens.json from cache at C:\\Users\\shahzehan/.cache\\huggingface\\transformers\\c4b7522f44ed8adb95e62288c6458da591654f7466e3ce2f9c730bb4087411d2.c1e7052e39d2135302ec27455f6db22e1520e6539942ff60a849c7f83f8ec6dc\n",
      "loading file https://huggingface.co/finiteautomata/bertweet-base-emotion-analysis/resolve/main/special_tokens_map.json from cache at C:\\Users\\shahzehan/.cache\\huggingface\\transformers\\01581144d9bf96cb9c7d8a77ee93c8b1f1095af5c1204b1b038a8cb0e3247aa8.0dc5b1041f62041ebbd23b1297f2f573769d5c97d8b7c28180ec86b8f6185aa8\n",
      "loading file https://huggingface.co/finiteautomata/bertweet-base-emotion-analysis/resolve/main/tokenizer_config.json from cache at C:\\Users\\shahzehan/.cache\\huggingface\\transformers\\1740697312c59fe96586f476c7765cd6f08516a6102ea96f22ffee64f7553234.c260b44e952f7f2a825aac395f2ebbed4ac9553800d1e320af246e81a548f37c\n",
      "loading configuration file https://huggingface.co/finiteautomata/bertweet-base-emotion-analysis/resolve/main/config.json from cache at C:\\Users\\shahzehan/.cache\\huggingface\\transformers\\c246eed05359b1a49c45955b0265b488e35b0cbd2628e3ead7dd54c8815162ee.a2dff24b4e0a884c6d58a09968c5b68e7391e749eb698ad92541818d420fd01b\n",
      "Model config RobertaConfig {\n",
      "  \"_name_or_path\": \"finiteautomata/bertweet-base-emotion-analysis\",\n",
      "  \"architectures\": [\n",
      "    \"RobertaForSequenceClassification\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"bos_token_id\": 0,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"others\",\n",
      "    \"1\": \"joy\",\n",
      "    \"2\": \"sadness\",\n",
      "    \"3\": \"anger\",\n",
      "    \"4\": \"surprise\",\n",
      "    \"5\": \"disgust\",\n",
      "    \"6\": \"fear\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"label2id\": {\n",
      "    \"anger\": 3,\n",
      "    \"disgust\": 5,\n",
      "    \"fear\": 6,\n",
      "    \"joy\": 1,\n",
      "    \"others\": 0,\n",
      "    \"sadness\": 2,\n",
      "    \"surprise\": 4\n",
      "  },\n",
      "  \"layer_norm_eps\": 1e-05,\n",
      "  \"max_position_embeddings\": 130,\n",
      "  \"model_type\": \"roberta\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"tokenizer_class\": \"BertweetTokenizer\",\n",
      "  \"transformers_version\": \"4.17.0\",\n",
      "  \"type_vocab_size\": 1,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 64001\n",
      "}\n",
      "\n",
      "Adding <mask> to the vocabulary\n",
      "loading configuration file https://huggingface.co/finiteautomata/bertweet-base-emotion-analysis/resolve/main/config.json from cache at C:\\Users\\shahzehan/.cache\\huggingface\\transformers\\c246eed05359b1a49c45955b0265b488e35b0cbd2628e3ead7dd54c8815162ee.a2dff24b4e0a884c6d58a09968c5b68e7391e749eb698ad92541818d420fd01b\n",
      "Model config RobertaConfig {\n",
      "  \"_name_or_path\": \"finiteautomata/bertweet-base-emotion-analysis\",\n",
      "  \"architectures\": [\n",
      "    \"RobertaForSequenceClassification\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"bos_token_id\": 0,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"others\",\n",
      "    \"1\": \"joy\",\n",
      "    \"2\": \"sadness\",\n",
      "    \"3\": \"anger\",\n",
      "    \"4\": \"surprise\",\n",
      "    \"5\": \"disgust\",\n",
      "    \"6\": \"fear\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"label2id\": {\n",
      "    \"anger\": 3,\n",
      "    \"disgust\": 5,\n",
      "    \"fear\": 6,\n",
      "    \"joy\": 1,\n",
      "    \"others\": 0,\n",
      "    \"sadness\": 2,\n",
      "    \"surprise\": 4\n",
      "  },\n",
      "  \"layer_norm_eps\": 1e-05,\n",
      "  \"max_position_embeddings\": 130,\n",
      "  \"model_type\": \"roberta\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"tokenizer_class\": \"BertweetTokenizer\",\n",
      "  \"transformers_version\": \"4.17.0\",\n",
      "  \"type_vocab_size\": 1,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 64001\n",
      "}\n",
      "\n",
      "loading weights file https://huggingface.co/finiteautomata/bertweet-base-emotion-analysis/resolve/main/pytorch_model.bin from cache at C:\\Users\\shahzehan/.cache\\huggingface\\transformers\\61c5894a0aca5ed63159e2ec6a5501db48124c1e6de287b82bc634334f031203.9c3c4c16d0dd174434d42471b9d4670734d982be506a06fc3111c12bee4380c7\n",
      "All model checkpoint weights were used when initializing RobertaForSequenceClassification.\n",
      "\n",
      "All the weights of RobertaForSequenceClassification were initialized from the model checkpoint at finiteautomata/bertweet-base-emotion-analysis.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use RobertaForSequenceClassification for predictions without further training.\n",
      "PyTorch: setting up devices\n",
      "The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n"
     ]
    }
   ],
   "source": [
    "sentiment_analyzer = create_analyzer(task=\"sentiment\", lang=\"en\")\n",
    "emotion_analyzer = create_analyzer(task=\"emotion\", lang=\"en\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2769c1d7-94d9-4bb5-a484-f30a85f52dd7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "19dfa98f99924784a2e1d4cdf0fe56f1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3247 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following columns in the test set  don't have a corresponding argument in `RobertaForSequenceClassification.forward` and have been ignored: text. If text are not expected by `RobertaForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Prediction *****\n",
      "  Num examples = 103901\n",
      "  Batch size = 32\n"
     ]
    }
   ],
   "source": [
    "# Jan 2020\n",
    "jan20_df = pd.read_csv(\"..\\\\processed\\\\tweets\\\\Jan2020.csv\", names=('text', 'label', 'topic'))\n",
    "out_list = []\n",
    "output = sentiment_analyzer.predict(jan20_df['text'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "67ef602d-ade5-452b-ad7a-60e4bc053391",
   "metadata": {},
   "outputs": [],
   "source": [
    "jan20_sen = [output[i].output for i in range(len(output))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "edf6e75d-65c8-4846-abd8-0623cfdb450c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "103901"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(jan20_sen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "db35cd2c-bff3-4413-b887-fc875fbb5f96",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0bd6d6e0aafb43019bd0c550731ad784",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3247 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following columns in the test set  don't have a corresponding argument in `RobertaForSequenceClassification.forward` and have been ignored: text. If text are not expected by `RobertaForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Prediction *****\n",
      "  Num examples = 103901\n",
      "  Batch size = 32\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='30444' max='3247' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3247/3247 75:53:21]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "output = emotion_analyzer.predict(jan20_df['text'])\n",
    "jan20_emo = [output[i].output for i in range(len(output))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "da9e75cd-dd5c-4291-96fc-99c1d21f1f5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "jan20_df['sentiment'] = jan20_sen\n",
    "jan20_df['emotion'] = jan20_emo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "1c2a76c3-bfe9-4802-9ea8-9df0d504025e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "      <th>topic</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>emotion</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Fast action will be key to containing new coro...</td>\n",
       "      <td>0</td>\n",
       "      <td>Masks</td>\n",
       "      <td>NEU</td>\n",
       "      <td>others</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>That CoronaVirus is about to turn into that Ri...</td>\n",
       "      <td>1</td>\n",
       "      <td>Quarantine</td>\n",
       "      <td>NEG</td>\n",
       "      <td>disgust</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>It be the ones who have the worst hygiene that...</td>\n",
       "      <td>1</td>\n",
       "      <td>Economy</td>\n",
       "      <td>NEG</td>\n",
       "      <td>disgust</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>This has been a day:\\n\\n• No new witnesses: ht...</td>\n",
       "      <td>1</td>\n",
       "      <td>Legislation</td>\n",
       "      <td>NEU</td>\n",
       "      <td>others</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>y’all @itslbern really thinks i have the coron...</td>\n",
       "      <td>1</td>\n",
       "      <td>Symptoms</td>\n",
       "      <td>NEG</td>\n",
       "      <td>fear</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  label        topic  \\\n",
       "0  Fast action will be key to containing new coro...      0        Masks   \n",
       "1  That CoronaVirus is about to turn into that Ri...      1   Quarantine   \n",
       "2  It be the ones who have the worst hygiene that...      1      Economy   \n",
       "3  This has been a day:\\n\\n• No new witnesses: ht...      1  Legislation   \n",
       "4  y’all @itslbern really thinks i have the coron...      1     Symptoms   \n",
       "\n",
       "  sentiment  emotion  \n",
       "0       NEU   others  \n",
       "1       NEG  disgust  \n",
       "2       NEG  disgust  \n",
       "3       NEU   others  \n",
       "4       NEG     fear  "
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jan20_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "b18fa885-00bb-448f-91f7-484c47745bd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "jan20_df.to_csv('..\\\\processed\\\\tweets\\\\Jan2020.csv', index = False, header = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "5a72a4c1-16d9-40e2-9e73-455d602212c2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ce62430044a9465cb9655d002a753ba8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3566 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following columns in the test set  don't have a corresponding argument in `RobertaForSequenceClassification.forward` and have been ignored: text. If text are not expected by `RobertaForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Prediction *****\n",
      "  Num examples = 114086\n",
      "  Batch size = 32\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "747b826723bc4510997c44a567d78f1a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3566 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following columns in the test set  don't have a corresponding argument in `RobertaForSequenceClassification.forward` and have been ignored: text. If text are not expected by `RobertaForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Prediction *****\n",
      "  Num examples = 114086\n",
      "  Batch size = 32\n"
     ]
    }
   ],
   "source": [
    "# Apr 2020\n",
    "df = pd.read_csv(\"..\\\\processed\\\\tweets\\\\Apr2020.csv\", names=('text', 'label', 'topic'))\n",
    "out1 = sentiment_analyzer.predict(df['text'])\n",
    "sen = [out1[i].output for i in range(len(out1))]\n",
    "out2 = emotion_analyzer.predict(df['text'])\n",
    "emo = [out2[i].output for i in range(len(out2))]\n",
    "df['sentiment'] = sen\n",
    "df['emotion'] = emo\n",
    "df.to_csv('..\\\\processed\\\\tweets\\\\Apr2020.csv', index = False, header = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "77aee05b-ca45-4ad4-a193-0e1c892f59a8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2000a57e61704762900617e2c3c97600",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3662 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following columns in the test set  don't have a corresponding argument in `RobertaForSequenceClassification.forward` and have been ignored: text. If text are not expected by `RobertaForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Prediction *****\n",
      "  Num examples = 117173\n",
      "  Batch size = 32\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b6dd6bbd49254ed0a682cb8285a1a0e9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3662 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following columns in the test set  don't have a corresponding argument in `RobertaForSequenceClassification.forward` and have been ignored: text. If text are not expected by `RobertaForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Prediction *****\n",
      "  Num examples = 117173\n",
      "  Batch size = 32\n"
     ]
    }
   ],
   "source": [
    "# Jul 2020\n",
    "df = pd.read_csv(\"..\\\\processed\\\\tweets\\\\Jul2020.csv\", names=('text', 'label', 'topic'))\n",
    "out1 = sentiment_analyzer.predict(df['text'])\n",
    "sen = [out1[i].output for i in range(len(out1))]\n",
    "out2 = emotion_analyzer.predict(df['text'])\n",
    "emo = [out2[i].output for i in range(len(out2))]\n",
    "df['sentiment'] = sen\n",
    "df['emotion'] = emo\n",
    "df.to_csv('..\\\\processed\\\\tweets\\\\Jul2020.csv', index = False, header = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "9d7edb96-13f8-42f4-83eb-db0e246642c4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d1b031e47afd4c8d8621e51b95d798e3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3696 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following columns in the test set  don't have a corresponding argument in `RobertaForSequenceClassification.forward` and have been ignored: text. If text are not expected by `RobertaForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Prediction *****\n",
      "  Num examples = 118246\n",
      "  Batch size = 32\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d12b0481287e4e2c9f0c6071ea387d77",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3696 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following columns in the test set  don't have a corresponding argument in `RobertaForSequenceClassification.forward` and have been ignored: text. If text are not expected by `RobertaForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Prediction *****\n",
      "  Num examples = 118246\n",
      "  Batch size = 32\n"
     ]
    }
   ],
   "source": [
    "# Oct 2020\n",
    "df = pd.read_csv(\"..\\\\processed\\\\tweets\\\\Oct2020.csv\", names=('text', 'label', 'topic'))\n",
    "out1 = sentiment_analyzer.predict(df['text'])\n",
    "sen = [out1[i].output for i in range(len(out1))]\n",
    "out2 = emotion_analyzer.predict(df['text'])\n",
    "emo = [out2[i].output for i in range(len(out2))]\n",
    "df['sentiment'] = sen\n",
    "df['emotion'] = emo\n",
    "df.to_csv('..\\\\processed\\\\tweets\\\\Oct2020.csv', index = False, header = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "c719df36-8f5f-42ef-8ad8-5ec4beb8a455",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b15e870461814889b101a5b2d5bf63e9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3922 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following columns in the test set  don't have a corresponding argument in `RobertaForSequenceClassification.forward` and have been ignored: text. If text are not expected by `RobertaForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Prediction *****\n",
      "  Num examples = 125479\n",
      "  Batch size = 32\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ac4b98154602410eb009fc1e10443cd8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3922 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following columns in the test set  don't have a corresponding argument in `RobertaForSequenceClassification.forward` and have been ignored: text. If text are not expected by `RobertaForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Prediction *****\n",
      "  Num examples = 125479\n",
      "  Batch size = 32\n"
     ]
    }
   ],
   "source": [
    "# Jan 2021\n",
    "df = pd.read_csv(\"..\\\\processed\\\\tweets\\\\Jan2021.csv\", names=('text', 'label', 'topic'))\n",
    "out1 = sentiment_analyzer.predict(df['text'])\n",
    "sen = [out1[i].output for i in range(len(out1))]\n",
    "out2 = emotion_analyzer.predict(df['text'])\n",
    "emo = [out2[i].output for i in range(len(out2))]\n",
    "df['sentiment'] = sen\n",
    "df['emotion'] = emo\n",
    "df.to_csv('..\\\\processed\\\\tweets\\\\Jan2021.csv', index = False, header = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "cf5025d5-fbbb-4c36-b8e5-7c879348851a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2b27cfd9996a4a2cb58a195458693f40",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4030 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following columns in the test set  don't have a corresponding argument in `RobertaForSequenceClassification.forward` and have been ignored: text. If text are not expected by `RobertaForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Prediction *****\n",
      "  Num examples = 128946\n",
      "  Batch size = 32\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7187a7dae35d4a9cbab59c42eb79767d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4030 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following columns in the test set  don't have a corresponding argument in `RobertaForSequenceClassification.forward` and have been ignored: text. If text are not expected by `RobertaForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Prediction *****\n",
      "  Num examples = 128946\n",
      "  Batch size = 32\n"
     ]
    }
   ],
   "source": [
    "# Apr 2021\n",
    "df = pd.read_csv(\"..\\\\processed\\\\tweets\\\\Apr2021.csv\", names=('text', 'label', 'topic'))\n",
    "out1 = sentiment_analyzer.predict(df['text'])\n",
    "sen = [out1[i].output for i in range(len(out1))]\n",
    "out2 = emotion_analyzer.predict(df['text'])\n",
    "emo = [out2[i].output for i in range(len(out2))]\n",
    "df['sentiment'] = sen\n",
    "df['emotion'] = emo\n",
    "df.to_csv('..\\\\processed\\\\tweets\\\\Apr2021.csv', index = False, header = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "117a0be9-44a3-408d-9d69-020a58cbff3e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0a4b3b0e2ebb49e1a6f065853f7128fd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4014 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following columns in the test set  don't have a corresponding argument in `RobertaForSequenceClassification.forward` and have been ignored: text. If text are not expected by `RobertaForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Prediction *****\n",
      "  Num examples = 128423\n",
      "  Batch size = 32\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "88866f40e5d94b8cae1f7426e4310c20",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4014 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following columns in the test set  don't have a corresponding argument in `RobertaForSequenceClassification.forward` and have been ignored: text. If text are not expected by `RobertaForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Prediction *****\n",
      "  Num examples = 128423\n",
      "  Batch size = 32\n"
     ]
    }
   ],
   "source": [
    "# Jul 2021\n",
    "df = pd.read_csv(\"..\\\\processed\\\\tweets\\\\Jul2021.csv\", names=('text', 'label', 'topic'))\n",
    "out1 = sentiment_analyzer.predict(df['text'])\n",
    "sen = [out1[i].output for i in range(len(out1))]\n",
    "out2 = emotion_analyzer.predict(df['text'])\n",
    "emo = [out2[i].output for i in range(len(out2))]\n",
    "df['sentiment'] = sen\n",
    "df['emotion'] = emo\n",
    "df.to_csv('..\\\\processed\\\\tweets\\\\Jul2021.csv', index = False, header = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "214494e5-d95a-4355-ba0f-3d26298cc46c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "46648dd45c7b4b4db5774328cf7efea9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4307 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following columns in the test set  don't have a corresponding argument in `RobertaForSequenceClassification.forward` and have been ignored: text. If text are not expected by `RobertaForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Prediction *****\n",
      "  Num examples = 137801\n",
      "  Batch size = 32\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "57612ecb51de422f85ca29f0d874e96b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4307 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following columns in the test set  don't have a corresponding argument in `RobertaForSequenceClassification.forward` and have been ignored: text. If text are not expected by `RobertaForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Prediction *****\n",
      "  Num examples = 137801\n",
      "  Batch size = 32\n"
     ]
    }
   ],
   "source": [
    "# Oct 2021\n",
    "df = pd.read_csv(\"..\\\\processed\\\\tweets\\\\Oct2021.csv\", names=('text', 'label', 'topic'))\n",
    "out1 = sentiment_analyzer.predict(df['text'])\n",
    "sen = [out1[i].output for i in range(len(out1))]\n",
    "out2 = emotion_analyzer.predict(df['text'])\n",
    "emo = [out2[i].output for i in range(len(out2))]\n",
    "df['sentiment'] = sen\n",
    "df['emotion'] = emo\n",
    "df.to_csv('..\\\\processed\\\\tweets\\\\Oct2021.csv', index = False, header = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1367f94-7eb7-48e8-b100-3da70f77a2b9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "0c53fb4d-a038-41e2-a18f-14b92708ca4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_sen(df, period, image_name):\n",
    "    dfa = df[df['topic'] == \"Masks\"]\n",
    "    dfap = round((dfa['sentiment'].value_counts()['POS'] / dfa['sentiment'].value_counts()) * 100, 2)\n",
    "    dfan = round((dfa['sentiment'].value_counts()['NEG'] / dfa['sentiment'].value_counts()) * 100, 2)\n",
    "    dfau = round((dfa['sentiment'].value_counts()['NEU'] / dfa['sentiment'].value_counts()) * 100, 2)\n",
    "\n",
    "    dfb = df[df['topic'] == \"Symptoms\"]\n",
    "    dfbp = round((dfb['sentiment'].value_counts()['POS'] / dfb['sentiment'].value_counts()) * 100, 2)\n",
    "    dfbn = round((dfb['sentiment'].value_counts()['NEG'] / dfb['sentiment'].value_counts()) * 100, 2)\n",
    "    dfbu = round((dfb['sentiment'].value_counts()['NEU'] / dfb['sentiment'].value_counts()) * 100, 2)\n",
    "\n",
    "    dfc = df[df['topic'] == \"Treatment\"]\n",
    "    dfcp = round((dfc['sentiment'].value_counts()['POS'] / dfc['sentiment'].value_counts()) * 100, 2)\n",
    "    dfcn = round((dfc['sentiment'].value_counts()['NEG'] / dfc['sentiment'].value_counts()) * 100, 2)\n",
    "    dfcu = round((dfc['sentiment'].value_counts()['NEU'] / dfc['sentiment'].value_counts()) * 100, 2)\n",
    "\n",
    "    dfd = df[df['topic'] == \"Science\"]\n",
    "    dfdp = round((dfd['sentiment'].value_counts()['POS'] / dfd['sentiment'].value_counts()) * 100, 2)\n",
    "    dfdn = round((dfd['sentiment'].value_counts()['NEG'] / dfd['sentiment'].value_counts()) * 100, 2)\n",
    "    dfdu = round((dfd['sentiment'].value_counts()['NEU'] / dfd['sentiment'].value_counts()) * 100, 2)\n",
    "\n",
    "    dfe = df[df['topic'] == \"Health\"]\n",
    "    dfep = round((dfe['sentiment'].value_counts()['POS'] / dfe['sentiment'].value_counts()) * 100, 2)\n",
    "    dfen = round((dfe['sentiment'].value_counts()['NEG'] / dfe['sentiment'].value_counts()) * 100, 2)\n",
    "    dfeu = round((dfe['sentiment'].value_counts()['NEU'] / dfe['sentiment'].value_counts()) * 100, 2)\n",
    "\n",
    "    dff = df[df['topic'] == \"Economy\"]\n",
    "    dffp = round((dff['sentiment'].value_counts()['POS'] / dff['sentiment'].value_counts()) * 100, 2)\n",
    "    dffn = round((dff['sentiment'].value_counts()['NEG'] / dff['sentiment'].value_counts()) * 100, 2)\n",
    "    dffu = round((dff['sentiment'].value_counts()['NEU'] / dff['sentiment'].value_counts()) * 100, 2)\n",
    "    \n",
    "    pos = [dfap, dfbp, dfcp, dfdp, dfep, dffp]\n",
    "    neg = [dfan, dfbn, dfcn, dfdn, dfen, dffn]\n",
    "    neu = [dfau, dfbu, dfcu, dfdu, dfeu, dffu]\n",
    "    \n",
    "    n=6\n",
    "    r = np.arange(n)\n",
    "    w = 0.25\n",
    "    \n",
    "    plt.bar(r, pos, color='#4594d0', width=w, edgecolor='black', label='Positive')\n",
    "    plt.bar(r+w, neg, color='#ecb77e', width=w, edgecolor='black', label='Negative')\n",
    "    plt.bar(r+w+w, neu, color='#c3ffa8', width=w, edgecolor='black', label='Neutral')\n",
    "    \n",
    "    plt.xlabel(\"Time Period\")\n",
    "    plt.ylabel(\"Sentiment Ration (%)\")\n",
    "    plt.title(\"{} Ratios of Sentiment per Topic\".format(period))\n",
    "    plt.xticks(r + width,['Masks','Symptoms','Treatment','Science','Health','Economy'])\n",
    "    plt.legend()\n",
    "    \n",
    "    plt.savefig(\"..\\\\processed\\\\images\\\\{}.png\".format(image_name), dpi=100)\n",
    "    \n",
    "def df2list(df):\n",
    "    dfa = df[df['emotion'] == \"joy\"]\n",
    "    dfb = df[df['emotion'] == \"sadness\"]\n",
    "    dfc = df[df['emotion'] == \"anger\"]\n",
    "    dfd = df[df['emotion'] == \"surprise\"]\n",
    "    dfe = df[df['emotion'] == \"disgust\"]\n",
    "    dff = df[df['emotion'] == \"fear\"]\n",
    "    df_out = pd.concat([dfa, dfb, dfc, dfd, dfe, dff])\n",
    "    out = df_out.iloc[:,4].tolist()\n",
    "    for i in range(len(out)):\n",
    "        if (out[i] == \"joy\"):\n",
    "            out[i] = 1\n",
    "        if (out[i] == \"sadness\"):\n",
    "            out[i] = 2\n",
    "        if (out[i] == \"anger\"):\n",
    "            out[i] = 3\n",
    "        if (out[i] == \"surprise\"):\n",
    "            out[i] = 4\n",
    "        if (out[i] == \"disgust\"):\n",
    "            out[i] = 5\n",
    "        if (out[i] == \"fear\"):\n",
    "            out[i] = 6\n",
    "    return out\n",
    "    \n",
    "def plot_emo(df, period, image_name):\n",
    "    df = df[df['label'] == 1]\n",
    "    dfa = df[df['topic'] == \"Masks\"]\n",
    "    dfb = df[df['topic'] == \"Symptoms\"]\n",
    "    dfc = df[df['topic'] == \"Treatment\"]\n",
    "    dfd = df[df['topic'] == \"Science\"]\n",
    "    dfe = df[df['topic'] == \"Health\"]\n",
    "    dff = df[df['topic'] == \"Economy\"]\n",
    "    \n",
    "    emo1 = df2list(dfa)\n",
    "    emo2 = df2list(dfb)\n",
    "    emo3 = df2list(dfc)\n",
    "    emo4 = df2list(dfd)\n",
    "    emo5 = df2list(dfe)\n",
    "    emo6 = df2list(dff)\n",
    "    \n",
    "    explode = [0.01, 0.01, 0.01, 0.01, 0.01, 0.01]\n",
    "    labels = ['Joy', 'Sadness', 'Anger', 'Surprise', 'Disgust', 'Fear']\n",
    "    \n",
    "    fig, axes = plt.subplots(2, 3, figsize=(20, 8))\n",
    "    \n",
    "    axes[0, 0].pie(emo1, labels=labels, explode=explode, autopct='%.0f%%')\n",
    "    axes[0, 0].title(\"Masks\")\n",
    "    \n",
    "    axes[0, 1].pie(emo1, labels=labels, explode=explode, autopct='%.0f%%')\n",
    "    axes[0, 1].title(\"Symptoms\")\n",
    "                     \n",
    "    axes[0, 2].pie(emo1, labels=labels, explode=explode, autopct='%.0f%%')\n",
    "    axes[0, 2].title(\"Treatment\")\n",
    "    \n",
    "    axes[1, 0].pie(emo1, labels=labels, explode=explode, autopct='%.0f%%')\n",
    "    axes[1, 0].title(\"Science\")\n",
    "    \n",
    "    axes[1, 1].pie(emo1, labels=labels, explode=explode, autopct='%.0f%%')\n",
    "    axes[1, 1].title(\"Health\")\n",
    "    \n",
    "    axes[1, 2].pie(emo1, labels=labels, explode=explode, autopct='%.0f%%')\n",
    "    axes[1, 2].title(\"Economy\")\n",
    "    \n",
    "    plt.title(\"{} Distribution of Emotions per Topic\".format(period))\n",
    "    plt.savefig(\"..\\\\processed\\\\images\\\\{}.png\".format(image_name), dpi=100)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "42fa918f-ec60-4bc2-bd93-309ba2537483",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "could not convert string to float: 'joy'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32mC:\\Users\\SHAHZE~1\\AppData\\Local\\Temp/ipykernel_5264/2854255366.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mdf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"..\\\\processed\\\\tweets\\\\Jan2020.csv\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnames\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'text'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'label'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'topic'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'sentiment'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'emotion'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;31m#plot_sen(df, \"January 2020\", \"jan2020sen\")\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mplot_emo\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"January 2020\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"jan2020emo\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mC:\\Users\\SHAHZE~1\\AppData\\Local\\Temp/ipykernel_5264/2735308605.py\u001b[0m in \u001b[0;36mplot_emo\u001b[1;34m(df, period, image_name)\u001b[0m\n\u001b[0;32m     82\u001b[0m     \u001b[0mfig\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxes\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msubplots\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m3\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfigsize\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m20\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m8\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     83\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 84\u001b[1;33m     \u001b[0maxes\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpie\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0memo1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlabels\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mexplode\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mexplode\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mautopct\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'%.0f%%'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     85\u001b[0m     \u001b[0maxes\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtitle\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Masks\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     86\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\miniconda3\\envs\\dick2\\lib\\site-packages\\matplotlib\\__init__.py\u001b[0m in \u001b[0;36minner\u001b[1;34m(ax, data, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1410\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0minner\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0max\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1411\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mdata\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1412\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0max\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0mmap\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msanitize_sequence\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1413\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1414\u001b[0m         \u001b[0mbound\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnew_sig\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbind\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0max\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\miniconda3\\envs\\dick2\\lib\\site-packages\\matplotlib\\axes\\_axes.py\u001b[0m in \u001b[0;36mpie\u001b[1;34m(self, x, explode, labels, colors, autopct, pctdistance, shadow, labeldistance, startangle, radius, counterclock, wedgeprops, textprops, center, frame, rotatelabels, normalize)\u001b[0m\n\u001b[0;32m   3040\u001b[0m         \u001b[1;31m# The use of float32 is \"historical\", but can't be changed without\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3041\u001b[0m         \u001b[1;31m# regenerating the test baselines.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3042\u001b[1;33m         \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3043\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3044\u001b[0m             \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"x must be 1D\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: could not convert string to float: 'joy'"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1440x576 with 6 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "df = df = pd.read_csv(\"..\\\\processed\\\\tweets\\\\Jan2020.csv\", names=('text', 'label', 'topic', 'sentiment', 'emotion'))\n",
    "#plot_sen(df, \"January 2020\", \"jan2020sen\")\n",
    "plot_emo(df, \"January 2020\", \"jan2020emo\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b1af252-699e-40e0-9e25-2ddfb3bd6e73",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
